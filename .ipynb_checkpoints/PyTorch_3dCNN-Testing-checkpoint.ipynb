{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load 3D CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 33371472\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "\n",
    "#This downloads the model from torchvision\n",
    "model = torchvision.models.video.r3d_18(pretrained=True, progress=True)\n",
    "\n",
    "print ('Total number of parameters: {}'.format(sum(p.numel() for p in model.parameters())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify the Last Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "model.fc = nn.Linear(in_features=512, out_features=10, bias=True)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import sys\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import json\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from PIL import Image, ImageOps\n",
    "import math\n",
    "import functools\n",
    "import copy\n",
    "import random\n",
    "import numbers\n",
    "import collections\n",
    "\n",
    "# DO NOT RUN THIS - SAMPLE DATA PROVIDED ALREADY CHANGED TO IMAGES\n",
    "# converting video data to jpg images (insert directory path of the video folder here)\n",
    "### Change directory path for input .avi video files folder (dir_path)\n",
    "'''\n",
    "def class_process(dir_path, dst_dir_path, class_name):\n",
    "    class_path = os.path.join(dir_path, class_name)\n",
    "    if not os.path.isdir(class_path):\n",
    "        return\n",
    "    \n",
    "    dst_class_path = os.path.join(dst_dir_path, class_name)\n",
    "    if not os.path.exists(dst_class_path):\n",
    "        os.mkdir(dst_class_path)\n",
    "    \n",
    "    for file_name in os.listdir(class_path):\n",
    "        if '.avi' not in file_name:\n",
    "            continue\n",
    "        name, ext = os.path.splitext(file_name)\n",
    "        dst_directory_path = os.path.join(dst_class_path, name)\n",
    "        video_file_path = os.path.join(class_path, file_name)\n",
    "        try:\n",
    "            if os.path.exists(dst_directory_path):\n",
    "                if not os.path.exists(os.path.join(dst_directory_path, 'image_00001.jpg')):\n",
    "                    subprocess.call('rm -r \\\"{}\\\"'.format(dst_directory_path), shell=True)\n",
    "                    print('remove {}'.format(dst_directory_path))\n",
    "                    os.mkdir(dst_directory_path)\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                os.mkdir(dst_directory_path)\n",
    "        except:\n",
    "            print(dst_directory_path)\n",
    "            continue\n",
    "        cmd = 'ffmpeg -i \\\"{}\\\" -vf scale=-1:240 \\\"{}/image_%05d.jpg\\\"'.format(video_file_path, dst_directory_path)\n",
    "        print(cmd)\n",
    "        subprocess.call(cmd, shell=True)\n",
    "        print('\\n')\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    dir_path = './sampleData/cichlid_videos/videos/'\n",
    "    dst_dir_path = './sampleData/cichlid_videos/jpg/'\n",
    "    \n",
    "    for class_name in os.listdir(dir_path):\n",
    "        class_process(dir_path, dst_dir_path, class_name)\n",
    "        \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN THIS - SAMPLE DATA PROVIDED ALREADY CHANGED TO IMAGES AND N_FRAMES CALCULATED\n",
    "## create n_frames file to indicate no of frames in each of the video folder.\n",
    "\n",
    "'''\n",
    "def class_process(dir_path, class_name):\n",
    "    class_path = os.path.join(dir_path, class_name)\n",
    "    if not os.path.isdir(class_path):\n",
    "        return\n",
    "\n",
    "    for file_name in os.listdir(class_path):\n",
    "        video_dir_path = os.path.join(class_path, file_name)\n",
    "        image_indices = []\n",
    "        for image_file_name in os.listdir(video_dir_path):\n",
    "            if 'image' not in image_file_name:\n",
    "                continue\n",
    "            image_indices.append(int(image_file_name[6:11]))\n",
    "        if len(image_indices) == 0:\n",
    "            print('no image files', video_dir_path)\n",
    "            n_frames = 0\n",
    "        else:\n",
    "            image_indices.sort(reverse=True)\n",
    "            n_frames = image_indices[0]\n",
    "            print(video_dir_path, n_frames)\n",
    "        with open(os.path.join(video_dir_path, 'n_frames'), 'w') as dst_file:\n",
    "            dst_file.write(str(n_frames))\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    dir_path = './jpg/'\n",
    "    for class_name in os.listdir(dir_path):\n",
    "        class_process(dir_path, class_name)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAMPLE DATA ALREADY CONTAINS JSON FILE FOR TESTING _ DO NOT RUN THIS\n",
    "## create JSON file from annotation path\n",
    "'''\n",
    "\n",
    "def convert_csv_to_dict(csv_dir_path, split_index):\n",
    "    database = {}\n",
    "    for filename in os.listdir(csv_dir_path):\n",
    "        if 'split{}'.format(split_index) not in filename:\n",
    "            continue\n",
    "        \n",
    "        data = pd.read_csv(os.path.join(csv_dir_path, filename),\n",
    "                           delimiter=' ', header=None)\n",
    "        keys = []\n",
    "        subsets = []\n",
    "        for i in range(data.shape[0]):\n",
    "            row = data.ix[i, :]\n",
    "            if row[1] == 0:\n",
    "                continue\n",
    "            elif row[1] == 1:\n",
    "                subset = 'training'\n",
    "            elif row[1] == 2:\n",
    "                subset = 'validation'\n",
    "            \n",
    "            keys.append(row[0].split('.')[0])\n",
    "            subsets.append(subset)        \n",
    "        \n",
    "        for i in range(len(keys)):\n",
    "            key = keys[i]\n",
    "            database[key] = {}\n",
    "            database[key]['subset'] = subsets[i]\n",
    "            label = '_'.join(filename.split('_')[:-2])\n",
    "            database[key]['annotations'] = {'label': label}\n",
    "    \n",
    "    return database\n",
    "\n",
    "def get_labels(csv_dir_path):\n",
    "    labels = []\n",
    "    for name in os.listdir(csv_dir_path):\n",
    "        labels.append('_'.join(name.split('_')[:-2]))\n",
    "    return sorted(list(set(labels)))\n",
    "\n",
    "def convert_hmdb51_csv_to_activitynet_json(csv_dir_path, split_index, dst_json_path):\n",
    "    labels = get_labels(csv_dir_path)\n",
    "    database = convert_csv_to_dict(csv_dir_path, split_index)\n",
    "    \n",
    "    dst_data = {}\n",
    "    dst_data['labels'] = labels\n",
    "    dst_data['database'] = {}\n",
    "    dst_data['database'].update(database)\n",
    "\n",
    "    with open(dst_json_path, 'w') as dst_file:\n",
    "        json.dump(dst_data, dst_file)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    csv_dir_path = './testTrainMulti_7030_splits/'\n",
    "\n",
    "    for split_index in range(1, 4):\n",
    "        dst_json_path = os.path.join(csv_dir_path, 'cichlids_{}.json'.format(split_index))\n",
    "        convert_hmdb51_csv_to_activitynet_json(csv_dir_path, split_index, dst_json_path)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DATASET class\n",
    "\n",
    "def pil_loader(path):\n",
    "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
    "    with open(path, 'rb') as f:\n",
    "        with Image.open(f) as img:\n",
    "            return img.convert('RGB')\n",
    "\n",
    "\n",
    "def accimage_loader(path):\n",
    "    try:\n",
    "        import accimage\n",
    "        return accimage.Image(path)\n",
    "    except IOError:\n",
    "        # Potentially a decoding problem, fall back to PIL.Image\n",
    "        return pil_loader(path)\n",
    "\n",
    "\n",
    "def get_default_image_loader():\n",
    "    from torchvision import get_image_backend\n",
    "    if get_image_backend() == 'accimage':\n",
    "        return accimage_loader\n",
    "    else:\n",
    "        return pil_loader\n",
    "\n",
    "\n",
    "def video_loader(video_dir_path, frame_indices, image_loader):\n",
    "    video = []\n",
    "    for i in frame_indices:\n",
    "        image_path = os.path.join(video_dir_path, 'image_{:05d}.jpg'.format(i))\n",
    "        if os.path.exists(image_path):\n",
    "            video.append(image_loader(image_path))\n",
    "        else:\n",
    "            return video\n",
    "\n",
    "    return video\n",
    "\n",
    "\n",
    "def get_default_video_loader():\n",
    "    image_loader = get_default_image_loader()\n",
    "    return functools.partial(video_loader, image_loader=image_loader)\n",
    "\n",
    "\n",
    "def load_annotation_data(data_file_path):\n",
    "    with open(data_file_path, 'r') as data_file:\n",
    "        return json.load(data_file)\n",
    "\n",
    "\n",
    "def get_class_labels(data):\n",
    "    class_labels_map = {}\n",
    "    index = 0\n",
    "    for class_label in data['labels']:\n",
    "        class_labels_map[class_label] = index\n",
    "        index += 1\n",
    "    return class_labels_map\n",
    "\n",
    "\n",
    "def get_video_names_and_annotations(data, subset):\n",
    "    video_names = []\n",
    "    annotations = []\n",
    "\n",
    "    for key, value in data['database'].items():\n",
    "        this_subset = value['subset']\n",
    "        if this_subset == subset:\n",
    "            label = value['annotations']['label']\n",
    "            video_names.append('{}/{}'.format(label, key))\n",
    "            annotations.append(value['annotations'])\n",
    "\n",
    "    return video_names, annotations\n",
    "\n",
    "def load_value_file(file_path):\n",
    "    with open(file_path, 'r') as input_file:\n",
    "        value = float(input_file.read().rstrip('\\n\\r'))\n",
    "\n",
    "    return value\n",
    "\n",
    "\n",
    "def make_dataset(root_path, annotation_path, subset, n_samples_for_each_video,\n",
    "                 sample_duration):\n",
    "    data = load_annotation_data(annotation_path)\n",
    "    video_names, annotations = get_video_names_and_annotations(data, subset)\n",
    "    class_to_idx = get_class_labels(data)\n",
    "    idx_to_class = {}\n",
    "    for name, label in class_to_idx.items():\n",
    "        idx_to_class[label] = name\n",
    "    dataset = []\n",
    "    for i in range(len(video_names)):\n",
    "        #print(video_names[i])\n",
    "        if i % 1000 == 0:\n",
    "            print('dataset loading [{}/{}]'.format(i, len(video_names)))\n",
    "\n",
    "        video_path = os.path.join(root_path, video_names[i])\n",
    "        if not os.path.exists(video_path):\n",
    "            continue\n",
    "\n",
    "        n_frames_file_path = os.path.join(video_path, 'n_frames')\n",
    "        n_frames = int(load_value_file(n_frames_file_path))\n",
    "        if n_frames <= 0:\n",
    "            continue\n",
    "\n",
    "        begin_t = 1\n",
    "        end_t = n_frames\n",
    "        sample = {\n",
    "            'video': video_path,\n",
    "            'segment': [begin_t, end_t],\n",
    "            'n_frames': n_frames,\n",
    "            'video_id': video_names[i].split('/')[1]\n",
    "        }\n",
    "        if len(annotations) != 0:\n",
    "            sample['label'] = class_to_idx[annotations[i]['label']]\n",
    "        else:\n",
    "            sample['label'] = -1\n",
    "\n",
    "        if n_samples_for_each_video == 1:\n",
    "            sample['frame_indices'] = list(range(1, n_frames + 1))\n",
    "            dataset.append(sample)\n",
    "        else:\n",
    "            if n_samples_for_each_video > 1:\n",
    "                step = max(1,\n",
    "                           math.ceil((n_frames - 1 - sample_duration) /\n",
    "                                     (n_samples_for_each_video - 1)))\n",
    "            else:\n",
    "                step = sample_duration\n",
    "            for j in range(1, n_frames, step):\n",
    "                sample_j = copy.deepcopy(sample)\n",
    "                sample_j['frame_indices'] = list(\n",
    "                    range(j, min(n_frames + 1, j + sample_duration)))\n",
    "                dataset.append(sample_j)\n",
    "\n",
    "    return dataset, idx_to_class\n",
    "\n",
    "\n",
    "class cichlids(Dataset):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        root (string): Root directory path.\n",
    "        spatial_transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        temporal_transform (callable, optional): A function/transform that  takes in a list of frame indices\n",
    "            and returns a transformed version\n",
    "        target_transform (callable, optional): A function/transform that takes in the\n",
    "            target and transforms it.\n",
    "        loader (callable, optional): A function to load an video given its path and frame indices.\n",
    "     Attributes:\n",
    "        classes (list): List of the class names.\n",
    "        class_to_idx (dict): Dict with items (class_name, class_index).\n",
    "        imgs (list): List of (image path, class_index) tuples\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 root_path,\n",
    "                 annotation_path,\n",
    "                 subset,\n",
    "                 n_samples_for_each_video=1,\n",
    "                 spatial_transforms=None,\n",
    "                 temporal_transform=None,\n",
    "                 target_transform=None,\n",
    "                 annotationDict = None,\n",
    "                 sample_duration=16,\n",
    "                 get_loader=get_default_video_loader):\n",
    "        self.data, self.class_names = make_dataset(\n",
    "            root_path, annotation_path, subset, n_samples_for_each_video,\n",
    "            sample_duration)\n",
    "\n",
    "        self.spatial_transforms = spatial_transforms\n",
    "        self.temporal_transform = temporal_transform\n",
    "        self.target_transform = target_transform\n",
    "        self.loader = get_loader()\n",
    "        self.annotationDict = annotationDict\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is class_index of the target class.\n",
    "        \"\"\"\n",
    "        \n",
    "        path = self.data[index]['video']\n",
    "        clip_name = path.rstrip().split('/')[-1]\n",
    "        frame_indices = self.data[index]['frame_indices']\n",
    "        if self.temporal_transform is not None:\n",
    "            frame_indices = self.temporal_transform(frame_indices)\n",
    "        clip = self.loader(path, frame_indices)\n",
    "        if self.spatial_transforms is not None:\n",
    "            self.spatial_transforms[self.annotationDict[clip_name]].randomize_parameters()\n",
    "            clip = [self.spatial_transforms[self.annotationDict[clip_name]](img) for img in clip]\n",
    "        clip = torch.stack(clip, 0).permute(1, 0, 2, 3)\n",
    "\n",
    "        target = self.data[index]\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        return clip, target, path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Transforms\n",
    "\n",
    "### Spatial Transform\n",
    "\n",
    "try:\n",
    "    import accimage\n",
    "except ImportError:\n",
    "    accimage = None\n",
    "\n",
    "\n",
    "class Compose(object):\n",
    "    \"\"\"Composes several transforms together.\n",
    "    Args:\n",
    "        transforms (list of ``Transform`` objects): list of transforms to compose.\n",
    "    Example:\n",
    "        >>> transforms.Compose([\n",
    "        >>>     transforms.CenterCrop(10),\n",
    "        >>>     transforms.ToTensor(),\n",
    "        >>> ])\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, img):\n",
    "        for t in self.transforms:\n",
    "            img = t(img)\n",
    "        return img\n",
    "\n",
    "    def randomize_parameters(self):\n",
    "        for t in self.transforms:\n",
    "            t.randomize_parameters()\n",
    "\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert a ``PIL.Image`` or ``numpy.ndarray`` to tensor.\n",
    "    Converts a PIL.Image or numpy.ndarray (H x W x C) in the range\n",
    "    [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0].\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, norm_value=255):\n",
    "        self.norm_value = norm_value\n",
    "\n",
    "    def __call__(self, pic):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            pic (PIL.Image or numpy.ndarray): Image to be converted to tensor.\n",
    "        Returns:\n",
    "            Tensor: Converted image.\n",
    "        \"\"\"\n",
    "        if isinstance(pic, np.ndarray):\n",
    "            # handle numpy array\n",
    "            img = torch.from_numpy(pic.transpose((2, 0, 1)))\n",
    "            # backward compatibility\n",
    "            return img.float().div(self.norm_value)\n",
    "\n",
    "        if accimage is not None and isinstance(pic, accimage.Image):\n",
    "            nppic = np.zeros(\n",
    "                [pic.channels, pic.height, pic.width], dtype=np.float32)\n",
    "            pic.copyto(nppic)\n",
    "            return torch.from_numpy(nppic)\n",
    "\n",
    "        # handle PIL Image\n",
    "        if pic.mode == 'I':\n",
    "            img = torch.from_numpy(np.array(pic, np.int32, copy=False))\n",
    "        elif pic.mode == 'I;16':\n",
    "            img = torch.from_numpy(np.array(pic, np.int16, copy=False))\n",
    "        else:\n",
    "            img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
    "        # PIL image mode: 1, L, P, I, F, RGB, YCbCr, RGBA, CMYK\n",
    "        if pic.mode == 'YCbCr':\n",
    "            nchannel = 3\n",
    "        elif pic.mode == 'I;16':\n",
    "            nchannel = 1\n",
    "        else:\n",
    "            nchannel = len(pic.mode)\n",
    "        img = img.view(pic.size[1], pic.size[0], nchannel)\n",
    "        # put it from HWC to CHW format\n",
    "        # yikes, this transpose takes 80% of the loading time/CPU\n",
    "        img = img.transpose(0, 1).transpose(0, 2).contiguous()\n",
    "        if isinstance(img, torch.ByteTensor):\n",
    "            return img.float().div(self.norm_value)\n",
    "        else:\n",
    "            return img\n",
    "\n",
    "    def randomize_parameters(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class Normalize(object):\n",
    "    \"\"\"Normalize an tensor image with mean and standard deviation.\n",
    "    Given mean: (R, G, B) and std: (R, G, B),\n",
    "    will normalize each channel of the torch.*Tensor, i.e.\n",
    "    channel = (channel - mean) / std\n",
    "    Args:\n",
    "        mean (sequence): Sequence of means for R, G, B channels respecitvely.\n",
    "        std (sequence): Sequence of standard deviations for R, G, B channels\n",
    "            respecitvely.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
    "        Returns:\n",
    "            Tensor: Normalized image.\n",
    "        \"\"\"\n",
    "        # TODO: make efficient\n",
    "        for t, m, s in zip(tensor, self.mean, self.std):\n",
    "            t.sub_(m).div_(s)\n",
    "        return tensor\n",
    "\n",
    "    def randomize_parameters(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class Scale(object):\n",
    "    \"\"\"Rescale the input PIL.Image to the given size.\n",
    "    Args:\n",
    "        size (sequence or int): Desired output size. If size is a sequence like\n",
    "            (w, h), output size will be matched to this. If size is an int,\n",
    "            smaller edge of the image will be matched to this number.\n",
    "            i.e, if height > width, then image will be rescaled to\n",
    "            (size * height / width, size)\n",
    "        interpolation (int, optional): Desired interpolation. Default is\n",
    "            ``PIL.Image.BILINEAR``\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size, interpolation=Image.BILINEAR):\n",
    "        assert isinstance(size,\n",
    "                          int) or (isinstance(size, collections.Iterable) and\n",
    "                                   len(size) == 2)\n",
    "        self.size = size\n",
    "        self.interpolation = interpolation\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (PIL.Image): Image to be scaled.\n",
    "        Returns:\n",
    "            PIL.Image: Rescaled image.\n",
    "        \"\"\"\n",
    "        if isinstance(self.size, int):\n",
    "            w, h = img.size\n",
    "            if (w <= h and w == self.size) or (h <= w and h == self.size):\n",
    "                return img\n",
    "            if w < h:\n",
    "                ow = self.size\n",
    "                oh = int(self.size * h / w)\n",
    "                return img.resize((ow, oh), self.interpolation)\n",
    "            else:\n",
    "                oh = self.size\n",
    "                ow = int(self.size * w / h)\n",
    "                return img.resize((ow, oh), self.interpolation)\n",
    "        else:\n",
    "            return img.resize(self.size, self.interpolation)\n",
    "\n",
    "    def randomize_parameters(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class CenterCrop(object):\n",
    "    \"\"\"Crops the given PIL.Image at the center.\n",
    "    Args:\n",
    "        size (sequence or int): Desired output size of the crop. If size is an\n",
    "            int instead of sequence like (h, w), a square crop (size, size) is\n",
    "            made.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size):\n",
    "        if isinstance(size, numbers.Number):\n",
    "            self.size = (int(size), int(size))\n",
    "        else:\n",
    "            self.size = size\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (PIL.Image): Image to be cropped.\n",
    "        Returns:\n",
    "            PIL.Image: Cropped image.\n",
    "        \"\"\"\n",
    "        w, h = img.size\n",
    "        th, tw = self.size\n",
    "        x1 = int(round((w - tw) / 2.))\n",
    "        y1 = int(round((h - th) / 2.))\n",
    "        return img.crop((x1, y1, x1 + tw, y1 + th))\n",
    "\n",
    "    def randomize_parameters(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class CornerCrop(object):\n",
    "\n",
    "    def __init__(self, size, crop_position=None):\n",
    "        self.size = size\n",
    "        if crop_position is None:\n",
    "            self.randomize = True\n",
    "        else:\n",
    "            self.randomize = False\n",
    "        self.crop_position = crop_position\n",
    "        self.crop_positions = ['c', 'tl', 'tr', 'bl', 'br']\n",
    "\n",
    "    def __call__(self, img):\n",
    "        image_width = img.size[0]\n",
    "        image_height = img.size[1]\n",
    "\n",
    "        if self.crop_position == 'c':\n",
    "            th, tw = (self.size, self.size)\n",
    "            x1 = int(round((image_width - tw) / 2.))\n",
    "            y1 = int(round((image_height - th) / 2.))\n",
    "            x2 = x1 + tw\n",
    "            y2 = y1 + th\n",
    "        elif self.crop_position == 'tl':\n",
    "            x1 = 0\n",
    "            y1 = 0\n",
    "            x2 = self.size\n",
    "            y2 = self.size\n",
    "        elif self.crop_position == 'tr':\n",
    "            x1 = image_width - self.size\n",
    "            y1 = 0\n",
    "            x2 = image_width\n",
    "            y2 = self.size\n",
    "        elif self.crop_position == 'bl':\n",
    "            x1 = 0\n",
    "            y1 = image_height - self.size\n",
    "            x2 = self.size\n",
    "            y2 = image_height\n",
    "        elif self.crop_position == 'br':\n",
    "            x1 = image_width - self.size\n",
    "            y1 = image_height - self.size\n",
    "            x2 = image_width\n",
    "            y2 = image_height\n",
    "\n",
    "        img = img.crop((x1, y1, x2, y2))\n",
    "\n",
    "        return img\n",
    "\n",
    "    def randomize_parameters(self):\n",
    "        if self.randomize:\n",
    "            self.crop_position = self.crop_positions[random.randint(\n",
    "                0,\n",
    "                len(self.crop_positions) - 1)]\n",
    "\n",
    "\n",
    "class RandomHorizontalFlip(object):\n",
    "    \"\"\"Horizontally flip the given PIL.Image randomly with a probability of 0.5.\"\"\"\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (PIL.Image): Image to be flipped.\n",
    "        Returns:\n",
    "            PIL.Image: Randomly flipped image.\n",
    "        \"\"\"\n",
    "        if self.p < 0.5:\n",
    "            return img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "        return img\n",
    "\n",
    "    def randomize_parameters(self):\n",
    "        self.p = random.random()\n",
    "\n",
    "\n",
    "class MultiScaleCornerCrop(object):\n",
    "    \"\"\"Crop the given PIL.Image to randomly selected size.\n",
    "    A crop of size is selected from scales of the original size.\n",
    "    A position of cropping is randomly selected from 4 corners and 1 center.\n",
    "    This crop is finally resized to given size.\n",
    "    Args:\n",
    "        scales: cropping scales of the original size\n",
    "        size: size of the smaller edge\n",
    "        interpolation: Default: PIL.Image.BILINEAR\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 scales,\n",
    "                 size,\n",
    "                 interpolation=Image.BILINEAR,\n",
    "                 crop_positions=['c', 'tl', 'tr', 'bl', 'br']):\n",
    "        self.scales = scales\n",
    "        self.size = size\n",
    "        self.interpolation = interpolation\n",
    "\n",
    "        self.crop_positions = crop_positions\n",
    "\n",
    "    def __call__(self, img):\n",
    "        min_length = min(img.size[0], img.size[1])\n",
    "        crop_size = int(min_length * self.scale)\n",
    "\n",
    "        image_width = img.size[0]\n",
    "        image_height = img.size[1]\n",
    "\n",
    "        if self.crop_position == 'c':\n",
    "            center_x = image_width // 2\n",
    "            center_y = image_height // 2\n",
    "            box_half = crop_size // 2\n",
    "            x1 = center_x - box_half\n",
    "            y1 = center_y - box_half\n",
    "            x2 = center_x + box_half\n",
    "            y2 = center_y + box_half\n",
    "        elif self.crop_position == 'tl':\n",
    "            x1 = 0\n",
    "            y1 = 0\n",
    "            x2 = crop_size\n",
    "            y2 = crop_size\n",
    "        elif self.crop_position == 'tr':\n",
    "            x1 = image_width - crop_size\n",
    "            y1 = 0\n",
    "            x2 = image_width\n",
    "            y2 = crop_size\n",
    "        elif self.crop_position == 'bl':\n",
    "            x1 = 0\n",
    "            y1 = image_height - crop_size\n",
    "            x2 = crop_size\n",
    "            y2 = image_height\n",
    "        elif self.crop_position == 'br':\n",
    "            x1 = image_width - crop_size\n",
    "            y1 = image_height - crop_size\n",
    "            x2 = image_width\n",
    "            y2 = image_height\n",
    "\n",
    "        img = img.crop((x1, y1, x2, y2))\n",
    "\n",
    "        return img.resize((self.size, self.size), self.interpolation)\n",
    "\n",
    "    def randomize_parameters(self):\n",
    "        self.scale = self.scales[random.randint(0, len(self.scales) - 1)]\n",
    "        self.crop_position = self.crop_positions[random.randint(\n",
    "            0,\n",
    "            len(self.crop_positions) - 1)]\n",
    "\n",
    "\n",
    "class MultiScaleRandomCrop(object):\n",
    "\n",
    "    def __init__(self, scales, size, interpolation=Image.BILINEAR):\n",
    "        self.scales = scales\n",
    "        self.size = size\n",
    "        self.interpolation = interpolation\n",
    "\n",
    "    def __call__(self, img):\n",
    "        min_length = min(img.size[0], img.size[1])\n",
    "        crop_size = int(min_length * self.scale)\n",
    "\n",
    "        image_width = img.size[0]\n",
    "        image_height = img.size[1]\n",
    "\n",
    "        x1 = self.tl_x * (image_width - crop_size)\n",
    "        y1 = self.tl_y * (image_height - crop_size)\n",
    "        x2 = x1 + crop_size\n",
    "        y2 = y1 + crop_size\n",
    "\n",
    "        img = img.crop((x1, y1, x2, y2))\n",
    "\n",
    "        return img.resize((self.size, self.size), self.interpolation)\n",
    "\n",
    "    def randomize_parameters(self):\n",
    "        self.scale = self.scales[random.randint(0, len(self.scales) - 1)]\n",
    "        self.tl_x = random.random()\n",
    "        self.tl_y = random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Transform\n",
    "\n",
    "class targetCompose(object):\n",
    "\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, target):\n",
    "        dst = []\n",
    "        for t in self.transforms:\n",
    "            dst.append(t(target))\n",
    "        return dst\n",
    "\n",
    "\n",
    "class ClassLabel(object):\n",
    "\n",
    "    def __call__(self, target):\n",
    "        return target['label']\n",
    "\n",
    "\n",
    "class VideoID(object):\n",
    "\n",
    "    def __call__(self, target):\n",
    "        return target['video_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal Transform\n",
    "\n",
    "class LoopPadding(object):\n",
    "\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "\n",
    "    def __call__(self, frame_indices):\n",
    "        out = frame_indices\n",
    "\n",
    "        for index in out:\n",
    "            if len(out) >= self.size:\n",
    "                break\n",
    "            out.append(index)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class TemporalBeginCrop(object):\n",
    "    \"\"\"Temporally crop the given frame indices at a beginning.\n",
    "    If the number of frames is less than the size,\n",
    "    loop the indices as many times as necessary to satisfy the size.\n",
    "    Args:\n",
    "        size (int): Desired output size of the crop.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "\n",
    "    def __call__(self, frame_indices):\n",
    "        out = frame_indices[:self.size]\n",
    "\n",
    "        for index in out:\n",
    "            if len(out) >= self.size:\n",
    "                break\n",
    "            out.append(index)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class TemporalCenterCrop(object):\n",
    "    \"\"\"Temporally crop the given frame indices at a center.\n",
    "    If the number of frames is less than the size,\n",
    "    loop the indices as many times as necessary to satisfy the size.\n",
    "    Args:\n",
    "        size (int): Desired output size of the crop.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "\n",
    "    def __call__(self, frame_indices):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            frame_indices (list): frame indices to be cropped.\n",
    "        Returns:\n",
    "            list: Cropped frame indices.\n",
    "        \"\"\"\n",
    "\n",
    "        center_index = len(frame_indices) // 2\n",
    "        begin_index = max(0, center_index - (self.size // 2))\n",
    "        end_index = min(begin_index + self.size, len(frame_indices))\n",
    "\n",
    "        out = frame_indices[begin_index:end_index]\n",
    "\n",
    "        for index in out:\n",
    "            if len(out) >= self.size:\n",
    "                break\n",
    "            out.append(index)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class TemporalRandomCrop(object):\n",
    "    \"\"\"Temporally crop the given frame indices at a random location.\n",
    "    If the number of frames is less than the size,\n",
    "    loop the indices as many times as necessary to satisfy the size.\n",
    "    Args:\n",
    "        size (int): Desired output size of the crop.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "\n",
    "    def __call__(self, frame_indices):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            frame_indices (list): frame indices to be cropped.\n",
    "        Returns:\n",
    "            list: Cropped frame indices.\n",
    "        \"\"\"\n",
    "\n",
    "        rand_end = max(0, len(frame_indices) - self.size - 1)\n",
    "        begin_index = random.randint(0, rand_end)\n",
    "        end_index = min(begin_index + self.size, len(frame_indices))\n",
    "\n",
    "        out = frame_indices[begin_index:end_index]\n",
    "\n",
    "        for index in out:\n",
    "            if len(out) >= self.size:\n",
    "                break\n",
    "            out.append(index)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Train, test and Val datasets\n",
    "\n",
    "def get_training_set(video_path, annotation_path, spatial_transform, temporal_transform, target_transform):\n",
    "    trainset = cichlids(video_path, annotation_path, 'training',1, spatial_transform, temporal_transform, target_transform)\n",
    "    return trainset\n",
    "\n",
    "def get_validation_set(opt, spatial_transform, temporal_transform, target_transform):\n",
    "    valset = cichlids(opt.video_path, opt.annotation_path, 'validation',1, opt.n_val_samples, spatial_transform, temporal_transform, target_transform, sample_duration=opt.sample_duration)\n",
    "    return valset\n",
    "\n",
    "def get_test_set(opt, spatial_transform, temporal_transform, target_transform):\n",
    "    assert opt.test_subset in ['val', 'test']\n",
    "\n",
    "    if opt.test_subset == 'val':\n",
    "        subset = 'validation'\n",
    "    elif opt.test_subset == 'test':\n",
    "        subset = 'testing'\n",
    "    \n",
    "    testset = cichlids(opt.video_path, opt.annotation_path, subset, 0, spatial_transform, temporal_transform, target_transform, sample_duration=opt.sample_duration)\n",
    "    return testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = [1.0]\n",
    "\n",
    "for i in range(1, 5):\n",
    "        scales.append(scales[-1] * 0.84089641525)\n",
    "        \n",
    "\n",
    "sample_size = 112\n",
    "sample_duration = 16\n",
    "scale_in_test = 1.0\n",
    "n_samples_for_each_video = 1\n",
    "crop_position_in_test = 'c'\n",
    "norm_method = Normalize([0, 0, 0], [1, 1, 1])\n",
    "crop_method = MultiScaleCornerCrop(scales, sample_size)\n",
    "\n",
    "\n",
    "\n",
    "video_path = './sampleData/cichlid_videos/jpg'\n",
    "annotation_path = './sampleData/cichlids.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_transform = Compose([crop_method, RandomHorizontalFlip(),ToTensor(), norm_method])                                \n",
    "temporal_transform = TemporalRandomCrop(sample_duration)\n",
    "target_transform = ClassLabel()\n",
    "\n",
    "trainset = cichlids(video_path, annotation_path, 'training', n_samples_for_each_video, spatial_transform, temporal_transform, target_transform)\n",
    "\n",
    "spatial_transform = Compose([Scale(sample_size), CenterCrop(sample_size), ToTensor(), norm_method])\n",
    "temporal_transform = LoopPadding(sample_duration)\n",
    "target_transform = ClassLabel()\n",
    "\n",
    "valset = cichlids(video_path, annotation_path, 'validation', n_samples_for_each_video, spatial_transform, temporal_transform, target_transform, sample_duration)\n",
    "\n",
    "\n",
    "spatial_transform = Compose([Scale(int(sample_size /scale_in_test)), CornerCrop(sample_size, crop_position_in_test), ToTensor(), norm_method])\n",
    "temporal_transform = LoopPadding(sample_duration)\n",
    "target_transform = VideoID()\n",
    "\n",
    "testset = cichlids(video_path, annotation_path, 'testing', 0, spatial_transform, temporal_transform, target_transform, sample_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating random data for testing purposes\n",
    "torch.manual_seed(7)\n",
    "trainData = torch.rand(10, 3, 2, 4, 4)*255\n",
    "trainLabels = torch.randint(0, 10, (10,))\n",
    "\n",
    "testData = torch.rand(10, 3, 2, 4, 4)*255\n",
    "testLabels = torch.randint(0, 10, (10,))\n",
    "\n",
    "# trainset_loader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=1)\n",
    "# valset_loader = DataLoader(valset, batch_size=64, shuffle=True, num_workers=1)\n",
    "# testset_loader = DataLoader(testset, batch_size=64, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def train_model(x, y, model, epochs=5):\n",
    "    model.train()\n",
    "    for t in range(epochs):\n",
    "        output = model(x)\n",
    "\n",
    "        loss = F.nll_loss(output, y)\n",
    "\n",
    "        # clear the gradients of all tensors being optimized.\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        # parameter update\n",
    "        optimizer.step()\n",
    "\n",
    "def check_accuracy(x, y, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    test_loss = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        scores = model(x)\n",
    "        test_loss += F.nll_loss(scores, y, size_average=False).item() # sum up batch loss\n",
    "        _, preds = scores.max(1)\n",
    "        num_correct += (preds == y).sum()\n",
    "        num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f), Loss: (%.2f)' % \n",
    "              (num_correct, num_samples, 100 * acc, float(test_loss) / num_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train (Finetune) the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(trainData, trainLabels, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1 / 10 correct (10.00), Loss: (-0.04)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vineeth/anaconda3/lib/python3.7/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "check_accuracy(testData, testLabels, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
